experiment:
  name: gpu_optimized
  seed: 42

data:
  nih_root: "datasets/NIH Chest X-Rays Master Datasets/archive"
  chexpert_root: "datasets/Standford ML Group X-Rays Chest Master Datasets/cheXphoto-master/cheXphoto-master"
  csv_path: "datasets/NIH Chest X-Rays Master Datasets/archive/Data_Entry_2017.csv"
  image_size: [320, 320]  # High-resolution input to preserve spatial fidelity of small nodules
  num_workers: 3  # Optimal for stability - 4 workers pushed memory to 94-96% (too risky)
  cache_dir: "datasets/cache"  # Pre-processed images cache (set to null to disable)
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  patient_split: true  # Patient-level splitting to prevent data leakage
  use_roi_extraction: true  # Will be disabled automatically if cache_dir is set

augmentations:
  horizontal_flip_prob: 0.5
  rotation_degrees: 10.0  # Limited to ±10° for anatomical plausibility (per thesis)
  random_noise_std: 0.02  # Increased noise for stronger regularization (was 0.01)
  use_gan_synthetic: false
  # Random Resized Crop (scale 0.9-1.0) is applied automatically in dataset

training:
  batch_size: 24  # Reduced to save memory (16GB RAM limit)
  max_epochs: 20  # Reduced from 25: if best metrics are at 8-15, 20 epochs gives buffer without wasting time
  precision: "16-mixed"  # Mixed precision for faster training on GPU (saves VRAM)
  accumulate_grad_batches: 4  # Recommended for 320x320 on 4GB VRAM
  optimizer: adamw
  learning_rate: 0.0001  # Hybrid Pressure: Return to v89 stable rate (1e-4) for better gradient path
  weight_decay: 0.01  # STABLE: Back to proven baseline value
  scheduler: cosine
  warmup_epochs: 5  # Gradually increase LR to stabilize DenseNet-121 backbone
  gradient_clip_val: 1.0  # CRITICAL: Prevent gradient explosion that causes model collapse
  use_weighted_sampling: false  # ASL handles imbalance, sampling not needed
  prediction_threshold: 0.15  # Lowered to increase Recall/Sensitivity - flags subtle pathologies for radiological review

model:
  backbone: densenet121
  pretrained: true
  dropout: 0.3  # INCREASED: Higher dropout to prevent overfitting after ASL fix (was 0.25)
  num_classes: 2
  class_weights: [1.0, 6.0]  # Strong emphasis on Fibrosis (<1.5% prevalence) - safe with clip=0.02 and gamma_pos=1.0

loss:
  name: asymmetric  # Asymmetric Loss (ASL) for extreme class imbalance
  gamma_neg: 4.0  # Focusing parameter for negative samples
  gamma_pos: 1.0  # Gradient Recovery: Reduced from 2.0 to allow confidence scores to grow naturally
  clip: 0.02  # Gradient Recovery: Reduced from 0.05 to increase gradient signal and "thaw" frozen gradients
